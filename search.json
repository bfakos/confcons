[{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://bfakos.github.io/confcons/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"confidence-and-consistency-what-are-they-and-why-using-them","dir":"Articles","previous_headings":"","what":"Confidence and consistency: what are they and why using them?","title":"Introduction to package 'confcons'","text":"‘confcons’ (confidence & consistency) light-weight, stand-alone R package designed calculate following two novel measures predictive/potential distribution models (incl. species distribution models): confidence measures proportion predictions model confident ; consistency measures consistent model confidence training evaluation subsets compared. confidence serves replacement widely criticized goodness--fit measures, AUC, consistency proxy model’s transferability (space time). measures can calculated balanced way, predicted presences predicted absences equally important. measures called confidence predictions (‘CP’) consistency (difference confidences ) predictions (‘DCP’); way weighted towards predicted presences, certain positive presences important selected modelling purpose. measures called confidence positive predictions (‘CPP’) consistency (difference confidences ) positive predictions (‘DCPP’). manuscript novel measures press scientific journal “Ecological Modelling”. published, ’ll cite , ’ll get much information measures paper.","code":""},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"functions-for-calculating-confidence-and-consistency","dir":"Articles","previous_headings":"","what":"Functions for calculating confidence and consistency","title":"Introduction to package 'confcons'","text":"Three small functions, thresholds(), confidence() consistency(), belong core package. wrapper function called measures() utilizes workhorse functions calculates every measures us optionally along traditional measures, AUC maxTSS. example ’ll see function work parameters returned value. details, please consult help page selected function examples given .","code":""},{"path":[]},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"introduction","dir":"Articles","previous_headings":"Workflow","what":"Introduction","title":"Introduction to package 'confcons'","text":", ’ll go main steps typical workflow : loading environmental presence-absence data using example dataset package ‘blockCV’; splitting dataset training evaluation subset using spatial blocks; training simple models training subset; making predictions whole dataset; evaluating models; interpreting measures. First, install package ‘confcons’ dependencies needed tutorial (incl. ‘terra’, ‘sf’, ‘blockCV’, ‘ranger’ ‘ROCR’): installed, can attach packages R session (suppress important warnings R version packages built):","code":"# install.packages(\"devtools\") devtools::install_github(repo = \"bfakos/confcons\", upgrade = \"never\", dependencies = TRUE) suppressWarnings(library(terra)) #> terra 1.7.71 suppressWarnings(library(sf)) #> Linking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE suppressWarnings(library(blockCV)) #> blockCV 3.1.3 suppressWarnings(library(ranger)) suppressWarnings(library(ROCR)) suppressWarnings(library(confcons))"},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"data-preparation","dir":"Articles","previous_headings":"Workflow","what":"Data preparation","title":"Introduction to package 'confcons'","text":"Let’s open environmental raster contains four climatic layers 5’ resolution GDA2020 (Geocentric Datum Australia) projection: open also occurrence data .csv file convert Simple Features: details dataset, please refer vignette package blockCV: Now split study region training evaluation parts using random spatial blocks convert resulted blocks Simple Features:  Let’s see presence absence points also polygons used training ones evaluation:  start build data.frame contain predictor values presence absence locations, observed occurrences, training mask (TRUE location later used model training, FALSE evaluation locations), predicted probabilities occurrence (later appended). raster::extract() gathers predictors studied locations us. blocks$folds[[1]] contains two vectors indices. ’ll use first vector training (second one evaluation).","code":"environment <- terra::rast(list.files(system.file(\"extdata/au/\", package = \"blockCV\"), full.names = TRUE)) terra::nlyr(environment) #> [1] 4 (predictors <- names(environment)) #> [1] \"bio_12\" \"bio_15\" \"bio_4\"  \"bio_5\" terra::crs(x = environment, describe = TRUE)$name #> [1] \"GDA2020 / GA LCC\" terra::res(environment) #> [1] 8558.341 8558.341 occurrences <- read.csv(system.file(\"extdata/\", \"species.csv\", package = \"blockCV\")) occurrences <- sf::st_as_sf(x = occurrences,                             coords = c(\"x\", \"y\"),                             crs = terra::crs(environment)) vignette(\"tutorial_1\") blocks <- blockCV::cv_spatial(x = occurrences,                               column = \"occ\",                               r = environment,                               size = 350000,                               k = 2,                               selection = \"random\",                               iteration = 50,                               seed = 12345,                               progress = FALSE,                               report = FALSE,                               plot = TRUE) blocks_sf <- sf::st_as_sf(x = blocks$blocks) plot(x = environment[[\"bio_5\"]], axes = FALSE, col = colorRampPalette(c(\"lightskyblue2\", \"lightyellow1\", \"rosybrown2\"))(255), colNA = \"gray95\") plot(x = occurrences[occurrences$occ == 1, ], pch = \"+\", col = \"darkgreen\", add = TRUE) plot(x = occurrences[occurrences$occ == 0, ], pch = \"+\", col = \"orange\", add = TRUE) plot(x = sf::st_geometry(blocks_sf[blocks_sf$folds == 1, ]), col = \"transparent\", border = \"royalblue1\", lwd = 2, add = TRUE) plot(x = sf::st_geometry(blocks_sf[blocks_sf$folds == 2, ]), col = \"transparent\", border = \"palevioletred1\", lwd = 2, add = TRUE) legend(x = -2100000,        y = -1300000,        legend = c(\"presence\", \"absence\", \"training\", \"evaluation\"),        col = c(\"darkgreen\", \"orange\", NA, NA),        pch = c(\"+\", \"+\", NA, NA),        border = c(NA, NA, \"royalblue1\", \"palevioletred1\"),        fill = c(NA, NA, \"transparent\", \"transparent\")) dataset <- as.data.frame(terra::extract(x = environment,                                         y = occurrences,                                         ID = FALSE)) dataset$occurrences <- occurrences$occ dataset$training_mask <- (1:nrow(occurrences)) %in% blocks$folds_list[[1]][[1]] str(dataset) #> 'data.frame':    500 obs. of  6 variables: #>  $ bio_12       : num  1287 1115 959 610 553 ... #>  $ bio_15       : num  93.8 118.6 85.1 22.8 15.4 ... #>  $ bio_4        : num  324 241 347 559 585 ... #>  $ bio_5        : num  31.2 29.4 28 31 31.4 ... #>  $ occurrences  : int  0 0 1 1 0 0 0 0 1 0 ... #>  $ training_mask: logi  TRUE TRUE FALSE FALSE TRUE TRUE ..."},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"training-models-and-making-predictions","dir":"Articles","previous_headings":"Workflow","what":"Training models and making predictions","title":"Introduction to package 'confcons'","text":"Now data.frame contains information needed train predictive distribution models. sake example, create two simple models: Generalized Linear Model (GLM) linear formula (.e., without interactions) stepwise predictor selection, Random Forest (RF) model 10000, 8-level trees (parameters deliberately set obtain overfitted model). GLM model trained training subset (dataset[dataset$training_mask, ]) studied locations used prediction (.e. training evaluation subsets). new column called ‘predictions_glm’ appended data.frame. repeat procedure, now training RF model:","code":"linear_formula <- as.formula(paste0(\"occurrences ~ \", paste(predictors, collapse = \" + \"))) model_glm <- step(trace = 0,                   object = glm(formula = linear_formula,                                family = binomial(link = \"logit\"),                                data = dataset[dataset$training_mask, ])) dataset$predictions_glm <- predict(object = model_glm,                                    newdata = dataset,                                    type = \"response\") model_rf <- ranger::ranger(formula = linear_formula,                            data = dataset[dataset$training_mask, ],                            num.trees = 10000,                            min.node.size = 10,                            max.depth = 8,                            seed = 12345,                            verbose = FALSE,                            classification = FALSE) dataset$predictions_rf <- predict(object = model_rf,                                   data = dataset,                                   type = \"response\",                                   verbose = FALSE)$predictions str(dataset[, c(\"occurrences\", \"training_mask\", \"predictions_glm\", \"predictions_rf\")]) #> 'data.frame':    500 obs. of  4 variables: #>  $ occurrences    : int  0 0 1 1 0 0 0 0 1 0 ... #>  $ training_mask  : logi  TRUE TRUE FALSE FALSE TRUE TRUE ... #>  $ predictions_glm: num  0.444 0.309 0.424 0.32 0.297 ... #>  $ predictions_rf : num  0.059859 0.334737 0.875771 0.00106 0.000338 ..."},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"evaluation-and-interpretation","dir":"Articles","previous_headings":"Workflow","what":"Evaluation and interpretation","title":"Introduction to package 'confcons'","text":"Models trained, predictions done, one step missing: evaluation. package ‘confcons’ become useful… Let’s take look lower (mean predicted value absence locations) upper (mean predicted value presence locations) thresholds /interpret predicted values certain negatives certain positives, respectively. use function thresholds() purpose, needs integer/logical vector observed predictions (called ‘observations’) numeric vector predicted probabilities occurrence (called ‘predictions’) input parameters. function returns two values (.e., named numeric vector length 2). 0.30 0.60, predictions GLM model can treated uncertain predictions. holds RF model 0.13 0.75. Now calculate two proposed evaluation measures, confidence positive predictions (CPP) confidence predictions (CP). calculated using evaluation subset. Function confidence() can calculate measures, depending value parameter ‘type’. ’s ‘positive’, ’ll get CPP, ’s ‘neutral’, ’ll get CP weighted towards positive predictions. Beyond ‘type’ two previously mentioned parameters (‘observations’ ‘predictions’) one parameter needed: ‘thresholds’. course, previously calculated thresholds perfectly suit purpose. much difference two measures. Whether use CPP CP describing confidence model depends main aim model. Confidence 0 1; higher value indicates confidence. GLM super confident, since CPP CP relatively far 1. bit curious whether confidence model higher lower calculated training subset. course, model confident training subset evaluation subset. absolutely normal (strange opposite occurs). evident difference two interpretation. consistency() function magic us: simple subtraction… needs one two confidence measures (CPP CP) training evaluation dataset, returns difference. negative value -1 0 normal. higher consistency (.e., closer 0), consistent model . Positive value might artifact indicates training evaluation subsets accidentally swapped. got familiar three core functions package: thresholds(), confidence() consistency(). question right ask: call three different functions several times want get measures model?. Well, don’t . wrapper function called measures() calculates everything us. needs three vectors: integer/logical vector observed occurrences (‘observations’), numeric vector predicted probabilities occurrence (‘predictions’), logical mask evaluation locations (‘evaluation_mask’). Previously calculated mask training locations, negation (!) perfectly match purpose: result named numeric vector containing measures. needed. recommended use ‘CPP_eval’ + ‘DCPP’, , predicted absences important predicted presences research, ‘CP_eval’ + ‘DCP’. can see RF model really confident (0.84) predictions training subset studied, confidence sharply drops switching evaluation subset (0.47). Hence, RF model consistent, warns us transferability issues might potentially occurs used extrapolation. GLM model much consistent (-0.19 vs. -0.37), select one extrapolation, e.g. climate change impact study. installed package ‘ROCR’, measures() can provide Area ROC Curve (AUC) maximum True Skill Statistic (maxTSS) us. simply switch parameter ‘goodness’ default value (FALSE) TRUE.","code":"(thresholds_glm <- thresholds(observations = dataset$occurrences,                               predictions = dataset$predictions_glm)) #> threshold1 threshold2  #>  0.2958127  0.6034773 (thresholds_rf <- thresholds(observations = dataset$occurrences,                              predictions = dataset$predictions_rf)) #> threshold1 threshold2  #>  0.1312359  0.7452445 conf_P_eval <- confidence(observations = dataset$occurrences[!dataset$training_mask],                           predictions = dataset$predictions_glm[!dataset$training_mask],                           thresholds = thresholds_glm,                           type = \"positive\") conf_P_eval #> [1] 0.49 conf_N_eval <- confidence(observations = dataset$occurrences[!dataset$training_mask],                           predictions = dataset$predictions_glm[!dataset$training_mask],                           thresholds = thresholds_glm,                           type = \"neutral\") conf_N_eval #> [1] 0.575 conf_P_train <- confidence(observations = dataset$occurrences[dataset$training_mask],                            predictions = dataset$predictions_glm[dataset$training_mask],                            thresholds = thresholds_glm,                            type = \"positive\") conf_P_train #> [1] 0.6803279 conf_P_eval < conf_P_train #> [1] TRUE consistency(conf_train = conf_P_train, conf_eval = conf_P_eval) #> [1] -0.1903279 measures(observations = dataset$occurrences,          predictions = dataset$predictions_glm,          evaluation_mask = !dataset$training_mask) #>   CP_train    CP_eval        DCP  CPP_train   CPP_eval       DCPP  #>  0.6829268  0.5750000 -0.1079268  0.6803279  0.4900000 -0.1903279 measures(observations = dataset$occurrences,          predictions = dataset$predictions_rf,          evaluation_mask = !dataset$training_mask) #>   CP_train    CP_eval        DCP  CPP_train   CPP_eval       DCPP  #>  0.8373984  0.5833333 -0.2540650  0.8373984  0.4680851 -0.3693133 measures(observations = dataset$occurrences,          predictions = dataset$predictions_glm,          evaluation_mask = !dataset$training_mask,          goodness = TRUE) #>   CP_train    CP_eval        DCP  CPP_train   CPP_eval       DCPP        AUC  #>  0.6829268  0.5750000 -0.1079268  0.6803279  0.4900000 -0.1903279  0.8403944  #>     maxTSS  #>  0.5696565"},{"path":"https://bfakos.github.io/confcons/articles/introduction_to_confcons.html","id":"evaluating-multiple-models","dir":"Articles","previous_headings":"Workflow","what":"Evaluating multiple models","title":"Introduction to package 'confcons'","text":"one another logical parameter, called ‘df’, can decide whether one-row data.frame suited analysis purposes. example, several models (.e., two example), can simply rbind() rows loop lapply(): lapply() solution:","code":"measures(observations = dataset$occurrences,          predictions = dataset$predictions_rf,          evaluation_mask = !dataset$training_mask,          goodness = TRUE,          df = TRUE) #>    CP_train   CP_eval       DCP CPP_train  CPP_eval       DCPP       AUC #> 1 0.8373984 0.5833333 -0.254065 0.8373984 0.4680851 -0.3693133 0.8131043 #>      maxTSS #> 1 0.5577608 model_IDs <- c(\"glm\", \"rf\") for (model_ID in model_IDs) {   column_name <- paste0(\"predictions_\", model_ID)   conf_and_cons <- measures(observations = dataset$occurrences,                             predictions = dataset[, column_name, drop = TRUE],                             evaluation_mask = !dataset$training_mask,                             df = TRUE)   if (model_ID == model_IDs[1]) {     conf_and_cons_df <- conf_and_cons   } else {     conf_and_cons_df <- rbind(conf_and_cons_df, conf_and_cons)   } } rownames(conf_and_cons_df) <- model_IDs conf_and_cons_df #>      CP_train   CP_eval        DCP CPP_train  CPP_eval       DCPP #> glm 0.6829268 0.5750000 -0.1079268 0.6803279 0.4900000 -0.1903279 #> rf  0.8373984 0.5833333 -0.2540650 0.8373984 0.4680851 -0.3693133 conf_and_cons_list <- lapply(X = model_IDs,                              FUN = function(model_ID) {                                column_name <- paste0(\"predictions_\", model_ID)                                measures(observations = dataset$occurrences,                                         predictions = dataset[, column_name, drop = TRUE],                                         evaluation_mask = !dataset$training_mask,                                         df = TRUE)                              }) conf_and_cons_df <- do.call(what = rbind,                             args = conf_and_cons_list) rownames(conf_and_cons_df) <- model_IDs conf_and_cons_df #>      CP_train   CP_eval        DCP CPP_train  CPP_eval       DCPP #> glm 0.6829268 0.5750000 -0.1079268 0.6803279 0.4900000 -0.1903279 #> rf  0.8373984 0.5833333 -0.2540650 0.8373984 0.4680851 -0.3693133"},{"path":"https://bfakos.github.io/confcons/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ákos Bede-Fazekas. Author, maintainer. Imelda Somodi. Author. Zoltán Botta-Dukát. Contributor.","code":""},{"path":"https://bfakos.github.io/confcons/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bede-Fazekas Á, Somodi (2024). confcons: Confidence Consistency Predictive Distribution Models. R package version 0.2.0, https://bfakos.github.io/confcons/, https://github.com/bfakos/confcons.","code":"@Manual{,   title = {confcons: Confidence and Consistency of Predictive Distribution Models},   author = {Ákos Bede-Fazekas and Imelda Somodi},   year = {2024},   note = {R package version 0.2.0, https://bfakos.github.io/confcons/},   url = {https://github.com/bfakos/confcons}, }"},{"path":"https://bfakos.github.io/confcons/index.html","id":"confcons","dir":"","previous_headings":"","what":"Confidence and Consistency of Predictive Distribution Models","title":"Confidence and Consistency of Predictive Distribution Models","text":"‘confcons’ (confidence & consistence) light-weight, stand-alone R package designed calculate following two novel measures predictive distribution models (incl. species distribution models): confidence measures proportion predictions model confident ; consistency measures consistent model confidence training evaluation subsets compared. confidence serves replacement widely criticized goodness--fit measures, AUC, consistency proxy model’s transferability (space time).","code":""},{"path":"https://bfakos.github.io/confcons/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Confidence and Consistency of Predictive Distribution Models","text":"can install development version ‘confcons’ GitHub : want read vignette R, install package :","code":"# install.packages(\"devtools\") devtools::install_github(repo = \"bfakos/confcons\", upgrade = \"never\") # install.packages(\"devtools\") devtools::install_github(repo = \"bfakos/confcons\", upgrade = \"never\", build_vignettes = TRUE)"},{"path":"https://bfakos.github.io/confcons/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Confidence and Consistency of Predictive Distribution Models","text":"Three small functions, thresholds(), confidence() consistency(), belong core package. wrapper function called measures() utilizes workhorse functions calculates every measures optionally along traditional measures, AUC maxTSS. Let’s say trained predictive distribution model made predictions , now want sure model confident predictions, confidence consistent training evaluation subsets, .e. might later use model extrapolation (space time). example dataset data.frame containing training evaluation subset. organized three columns: observations (integer): observed presences (1s) absences (0s), predictions (numeric): predicted probability occurrences (within [0, 1] interval), evaluation_mask (logical): indicates whether certain row belongs evaluation subset (TRUE) training subset (FALSE). Well, really small dataset… Let’s attach package R session: Now can calculate measures: function returns pair confidence values training subset (CP_train, CPP_train) just information; pair confidence values evaluation subset (CP_eval, CPP_eval), describing confidence model; pair consistency values (DCP, DCPP) serve proxies transferability model. difference two values forming pairs described scientific publication (TBD). model seems super perfect, less confident positive predictions (.e. predicted presences), since CPP_eval closer 1 0. Even absolutely confident, really consistent (.e., DCPP close 0), might afraid transferability issues used spatial temporal extrapolation. detailed description measures functions ‘confcons’, examples can found vignette.","code":"dataset <- data.frame(     observations = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L),     predictions = c(0.1, 0.2, 0.4, 0.5, 0.5, 0.2, 0.3, 0.3, 0.4, 0.3, 0.65, 0.9, 0.9, 1, 0.1, 0.5, 0.8, 0.8),     evaluation_mask = c(FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE) ) library(confcons) measures(observations = dataset$observations,                  predictions = dataset$predictions,                  evaluation_mask = dataset$evaluation_mask) #>    CP_train     CP_eval         DCP   CPP_train    CPP_eval        DCPP  #>  0.80000000  0.75000000 -0.05000000  0.75000000  0.66666667 -0.08333333"},{"path":"https://bfakos.github.io/confcons/index.html","id":"package-lifecycle-and-contribution","dir":"","previous_headings":"","what":"Package lifecycle and contribution","title":"Confidence and Consistency of Predictive Distribution Models","text":"GitHub version package now stable state. manuscript novel measures, confidence consistency, press scientific journal “Ecological Modelling”. Upon acceptance aim publish ‘confcons’ CRAN. find bug feature request, also idea want discuss authors package, please create new issue.","code":""},{"path":"https://bfakos.github.io/confcons/reference/confidence.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence of the predictive distribution model — confidence","title":"Confidence of the predictive distribution model — confidence","text":"Calculate confidence positive predictions within known presences (CPP, type = \"positive\") confidence predictions within known presences (CP, type = \"neutral\") based occurrence observations, predictions probability occurrence, two thresholds distinguishing certain negatives/positives uncertain predictions.","code":""},{"path":"https://bfakos.github.io/confcons/reference/confidence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence of the predictive distribution model — confidence","text":"","code":"confidence(   observations,   predictions,   thresholds = confcons::thresholds(observations = observations, predictions =     predictions),   type = \"positive\" )"},{"path":"https://bfakos.github.io/confcons/reference/confidence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence of the predictive distribution model — confidence","text":"observations Either integer logical vector containing binary observations presences encoded 1s/TRUEs absences 0s/FALSEs. predictions numeric vector containing predicted probabilities occurrence typically within [0, 1] interval. length(predictions) equal length(observations) order elements match. thresholds numeric vector length two, typically calculated thresholds(). first element distinguishes certain negatives (certain absences) uncertain predictions. second element distinguishes certain positives (certain presences) uncertain predictions. missing, confcons::thresholds(observations = observations, predictions = predictions) called, see section 'Note' use default value. type character vector length one containing value \"positive\" (calculating confidence positive predictions within known presences (CPP)) \"neutral\" (calculating confidence predictions within known presences (CP)). Defaults \"positive\".","code":""},{"path":"https://bfakos.github.io/confcons/reference/confidence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence of the predictive distribution model — confidence","text":"numeric vector length one. either NA_real_ positive   number within [0, 1] interval. Larger value indicates   model confident.","code":""},{"path":"https://bfakos.github.io/confcons/reference/confidence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Confidence of the predictive distribution model — confidence","text":"Technically, confidence can calculated training subset,   evaluation subset, whole dataset well. Note, however,   much sense calculate confidence training subset, except   using result consistency calculation. need   confidence measure, calculate evaluation subset using   thresholds previously determined whole dataset (.e.,   use default value parameter thresholds). See last   example vignette.","code":""},{"path":[]},{"path":"https://bfakos.github.io/confcons/reference/confidence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidence of the predictive distribution model — confidence","text":"","code":"set.seed(12345)  # Using logical observations, default 'thresholds' and 'type' parameter: observations_1000_logical <- c(rep(x = FALSE, times = 500),                                rep(x = TRUE, times = 500)) predictions_1000 <- c(runif(n = 500, min = 0, max = 0.7),                       runif(n = 500, min = 0.3, max = 1)) confidence(observations = observations_1000_logical,            predictions = predictions_1000) # 0.561 #> [1] 0.5607064  # Using integer observations, default 'thresholds' parameter, # both 'positive' and 'neutral' confidence type: observations_4000_integer <- c(rep(x = 0L, times = 3000),                                rep(x = 1L, times = 1000)) predictions_4000 <- c(runif(n = 3000, min = 0, max = 0.8),                       runif(n = 1000, min = 0.2, max = 0.9)) confidence(observations = observations_4000_integer,            predictions = predictions_4000, type = \"positive\") # 0.691 #> [1] 0.6912378 confidence(observations = observations_4000_integer,            predictions = predictions_4000, type = \"neutral\") # 0.778 #> [1] 0.778  # Using some previously selected thresholds: strict_thresholds <- c(0.1, 0.9) permissive_thresholds <- c(0.4, 0.5) percentile_thresholds <- quantile(x = predictions_4000[observations_4000_integer == 1],                                   probs = c(0.1, 0.9)) # 10th and 90th percentile confidence(observations = observations_4000_integer,            predictions = predictions_4000,            thresholds = strict_thresholds,            type = \"neutral\") # 0 #> [1] 0 confidence(observations = observations_4000_integer,            predictions = predictions_4000,            thresholds = permissive_thresholds,            type = \"neutral\") # 0.836 #> [1] 0.836 confidence(observations = observations_4000_integer,            predictions = predictions_4000,            thresholds = percentile_thresholds,            type = \"neutral\") # 0.2 #> [1] 0.2  # Real-life case # (thresholds calculated from the whole dataset, confidence from the evaluation subset): dataset <- data.frame(   observations = observations_4000_integer,   predictions = predictions_4000,   evaluation_mask = c(rep(x = FALSE, times = 250),                       rep(x = TRUE, times = 250),                       rep(x = FALSE, times = 250),                       rep(x = TRUE, times = 250)) ) thresholds_whole <- thresholds(observations = dataset$observations,                                predictions = dataset$predictions) (confidence_evaluation <- confidence(observations = dataset$observations[dataset$evaluation_mask],                                      predictions = dataset$predictions[dataset$evaluation_mask],                                      thresholds = thresholds_whole)) # 0.671 #> [1] 0.6713092  # Wrong parameterization: if (FALSE) { confidence(observations = observations_1000_logical,            predictions = predictions_1000,            type = \"pos\") # error confidence(observations = observations_1000_logical,            predictions = predictions_1000,            thresholds = c(0.2, NA_real_)) # warning confidence(observations = observations_1000_logical,            predictions = predictions_1000,            thresholds = c(-0.4, 0.85)) # warning confidence(observations = observations_1000_logical,            predictions = predictions_1000,            thresholds = c(0.6, 0.3)) # warning confidence(observations = observations_1000_logical,            predictions = predictions_4000) # error set.seed(12345) observations_4000_numeric <- c(rep(x = 0, times = 3000),                                rep(x = 1, times = 1000)) predictions_4000_strange <- c(runif(n = 3000, min = -0.3, max = 0.4),                               runif(n = 1000, min = 0.6, max = 1.5)) confidence(observations = observations_4000_numeric,            predictions = predictions_4000_strange,            thresholds = c(0.2, 0.7)) # multiple warnings mask_of_normal_predictions <- predictions_4000_strange >= 0 & predictions_4000_strange <= 1 confidence(observations = as.integer(observations_4000_numeric)[mask_of_normal_predictions],            predictions = predictions_4000_strange[mask_of_normal_predictions],            thresholds = c(0.2, 0.7)) # OK }"},{"path":"https://bfakos.github.io/confcons/reference/consistency.html","id":null,"dir":"Reference","previous_headings":"","what":"Consistency of the predictive distribution model — consistency","title":"Consistency of the predictive distribution model — consistency","text":"Calculate consistency (DCPP, DCP) model difference confidence calculated evaluation confidence calculated training subset. Consistency serves proxy model's transferability.","code":""},{"path":"https://bfakos.github.io/confcons/reference/consistency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consistency of the predictive distribution model — consistency","text":"","code":"consistency(conf_train, conf_eval)"},{"path":"https://bfakos.github.io/confcons/reference/consistency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consistency of the predictive distribution model — consistency","text":"conf_train Confidence calculated training subset: numeric vector length one, containing number within [0, 1] interval. Typically calculated function confidence() using training subset. conf_eval Confidence calculated evaluation subset: numeric vector length one, containing number within [0, 1] interval. Typically calculated function confidence() using evaluation subset.","code":""},{"path":"https://bfakos.github.io/confcons/reference/consistency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Consistency of the predictive distribution model — consistency","text":"numeric vector length one. either NA_real_ number   within [-1, 1] interval. Typically, falls within  [-1, 0] interval. Greater value indicates   consistent/transferable model. .e, closer returned value -1,   less consistence/transferable model . Value 0 might   artifact might indicate training evaluation subsets   accidentally swapped.","code":""},{"path":[]},{"path":"https://bfakos.github.io/confcons/reference/consistency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Consistency of the predictive distribution model — consistency","text":"","code":"# Simple examples: consistency(conf_train = 0.93,             conf_eval = 0.21) # -0.72 - hardly consistent/transferable model #> [1] -0.72 consistency(conf_train = 0.43,             conf_eval = 0.35) # -0.08 - consistent/transferable model, although not so confident #> [1] -0.08 consistency(conf_train = 0.87,             conf_eval = 0.71) # -0.16 - a consistent/transferable model that is confident as well #> [1] -0.16 consistency(conf_train = 0.67,             conf_eval = 0.78) # 0.11 - positive value might be an artifact #> [1] 0.11 consistency(conf_train = 0.67,             conf_eval = NA_real_) # NA #> Warning: Parameter 'conf_eval' is expected to fall within the [0, 1] interval, but found to be NA. #> [1] NA  # Real-life case: set.seed(12345) observations <- c(rep(x = FALSE, times = 500),                  rep(x = TRUE, times = 500)) predictions <- c(runif(n = 500, min = 0, max = 0.7),                  runif(n = 500, min = 0.3, max = 1)) dataset <- data.frame(   observations = observations,   predictions = predictions,   evaluation_mask = c(rep(x = FALSE, times = 250),                       rep(x = TRUE, times = 250),                       rep(x = FALSE, times = 250),                       rep(x = TRUE, times = 250)) ) thresholds_whole <- thresholds(observations = dataset$observations,                                predictions = dataset$predictions) confidence_training <- confidence(observations = dataset$observations[!dataset$evaluation_mask],                                   predictions = dataset$predictions[!dataset$evaluation_mask],                                   thresholds = thresholds_whole) # 0.602 confidence_evaluation <- confidence(observations = dataset$observations[dataset$evaluation_mask],                                     predictions = dataset$predictions[dataset$evaluation_mask],                                     thresholds = thresholds_whole) # 0.520 consistency(conf_train = confidence_training,             conf_eval = confidence_evaluation) # -0.083 - consistent/transferable model #> [1] -0.08302792  # Wrong parameterization: if (FALSE) { consistency(conf_train = 1.3,             conf_eval = 0.5) # warning consistency(conf_train = 0.6,             conf_eval = c(0.4, 0.5)) # warning }"},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Goodness-of-fit, confidence and consistency measures — measures","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"Wrapper function calculating predictive distribution model's confidence, consistency, optionally well-known goodness--fit measures well. calculated measures follows: confidence predictions (CP) confidence positive predictions (CPP) within known presences training evaluation subsets consistency predictions (difference CPs; DCP) positive predictions (difference CPPs; DCPP) Area ROC Curve (AUC) - optional (see parameter goodness) maximum True Skill Statistic (maxTSS) - optional (see parameter goodness)","code":""},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"","code":"measures(   observations,   predictions,   evaluation_mask,   goodness = FALSE,   df = FALSE )"},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"observations Either integer logical vector containing binary observations presences encoded 1s/TRUEs absences 0s/FALSEs. predictions numeric vector containing predicted probabilities occurrence typically within [0, 1] interval. length(predictions) equal length(observations) order elements match. evaluation_mask logical vector (mask) evaluation subset. ith element indicates whether  ith element observations used evaluation (TRUE) training (FALSE). length(evaluation_mask) equal length(observations) order elements match, .e. observations[evaluation_mask] evaluation subset observations[!evaluation_mask] training subset. goodness Logical vector length one, defaults FALSE. Indicates, whether goodness--fit measures (AUC maxTSS) calculated. set TRUE, external package ROCR (Sing et al. 2005) needed calculation (see section 'Note'). df Logical vector length one, defaults FALSE. Indicates, whether returned value one-row data.frame rbind()able measures() called multiple models loop lapply(). See section 'Value' 'Examples' details.","code":""},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"named numeric vector (df FALSE; default)   data.frame (df TRUE) one row.  length() vector ncol() data.frame   6 (goodness FALSE; default) 8 ( goodness TRUE). name elements/columns   follows: CP_train confidence predictions within known   presences (CP) training subset CP_eval confidence   predictions within known presences (CP) evaluation subset DCP consistency predictions (difference CPs) CPP_train confidence   positive predictions within known presences (CPP) training subset CPP_eval confidence positive predictions within known presences   (CPP) evaluation subset DCPP consistency positive   predictions (difference CPPs) AUC Area ROC Curve (Hanley McNeil 1982;   calculated ROCR::performance()).   element/column available parameter 'goodness' set   TRUE. package ROCR available parameter   'goodness' set TRUE, value AUC   NA_real_ warning raised. maxTSS Maximum True   Skill Statistic (Allouche et al. 2006; calculated   ROCR::performance()). element/column   available parameter 'goodness' set TRUE.   package ROCR available parameter 'goodness' set   TRUE, value maxTSS NA_real_ warning   raised.","code":""},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"Since confcons light-weight, stand-alone packages,   import package ROCR (Sing et al. 2005), .e. installing   confcons mean installing ROCR automatically.   need AUC maxTSS (.e., parameter 'goodness' set   TRUE), install ROCR install confcons along   dependencies (.e., devtools::install_github(repo =   \"bfakos/confcons\", dependencies = TRUE)).","code":""},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"Allouche O, Tsoar , Kadmon R (2006): Assessing   accuracy species distribution models: prevalence, kappa true   skill statistic (TSS). Journal Applied Ecology 43(6): 1223-1232.   DOI:   10.1111/j.1365-2664.2006.01214.x. Hanley JA, McNeil BJ (1982):   meaning use area receiver operating characteristic (ROC)   curve. Radiology 143(1): 29-36.   DOI:   10.1148/radiology.143.1.7063747. Sing T, Sander O, Beerenwinkel N,   Lengauer T. (2005): ROCR: visualizing classifier performance R.   Bioinformatics 21(20): 3940-3941.   DOI:   10.1093/bioinformatics/bti623.","code":""},{"path":[]},{"path":"https://bfakos.github.io/confcons/reference/measures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Goodness-of-fit, confidence and consistency measures — measures","text":"","code":"set.seed(12345) dataset <- data.frame(   observations = c(rep(x = FALSE, times = 500),                   rep(x = TRUE, times = 500)),   predictions_model1 = c(runif(n = 250, min = 0, max = 0.6),                         runif(n = 250, min = 0.1, max = 0.7),                         runif(n = 250, min = 0.4, max = 1),                         runif(n = 250, min = 0.3, max = 0.9)),   predictions_model2 = c(runif(n = 250, min = 0.1, max = 0.55),                         runif(n = 250, min = 0.15, max = 0.6),                         runif(n = 250, min = 0.3, max = 0.9),                         runif(n = 250, min = 0.25, max = 0.8)),   evaluation_mask = c(rep(x = FALSE, times = 250),                       rep(x = TRUE, times = 250),                       rep(x = FALSE, times = 250),                       rep(x = TRUE, times = 250)) )  # Default parameterization, return a vector without AUC and maxTSS: conf_and_cons <- measures(observations = dataset$observations,                           predictions = dataset$predictions_model1,                           evaluation_mask = dataset$evaluation_mask) print(conf_and_cons) #>   CP_train    CP_eval        DCP  CPP_train   CPP_eval       DCPP  #>  0.6120000  0.4760000 -0.1360000  0.6120000  0.4229075 -0.1890925  names(conf_and_cons) #> [1] \"CP_train\"  \"CP_eval\"   \"DCP\"       \"CPP_train\" \"CPP_eval\"  \"DCPP\"      conf_and_cons[c(\"CPP_eval\", \"DCPP\")] #>   CPP_eval       DCPP  #>  0.4229075 -0.1890925   # Calculate AUC and maxTSS as well if package ROCR is installed: if (requireNamespace(package = \"ROCR\", quietly = TRUE)) {   conf_and_cons_and_goodness <- measures(observations = dataset$observations,                                          predictions = dataset$predictions_model1,                                          evaluation_mask = dataset$evaluation_mask,                                          goodness = TRUE) }  # Calculate the measures for multiple models in a for loop: model_IDs <- as.character(1:2) for (model_ID in model_IDs) {   column_name <- paste0(\"predictions_model\", model_ID)   conf_and_cons <- measures(observations = dataset$observations,                             predictions = dataset[, column_name, drop = TRUE],                             evaluation_mask = dataset$evaluation_mask,                             df = TRUE)   if (model_ID == model_IDs[1]) {     conf_and_cons_df <- conf_and_cons   } else {     conf_and_cons_df <- rbind(conf_and_cons_df, conf_and_cons)   } } conf_and_cons_df #>   CP_train CP_eval    DCP CPP_train  CPP_eval       DCPP #> 1    0.612   0.476 -0.136 0.6120000 0.4229075 -0.1890925 #> 2    0.668   0.568 -0.100 0.6391304 0.4653465 -0.1737839  # Calculate the measures for multiple models in a lapply(): conf_and_cons_list <- lapply(X = model_IDs,                              FUN = function(model_ID) {                                column_name <- paste0(\"predictions_model\", model_ID)                                measures(observations = dataset$observations,                                         predictions = dataset[, column_name, drop = TRUE],                                         evaluation_mask = dataset$evaluation_mask,                                         df = TRUE)                              }) conf_and_cons_df <- do.call(what = rbind,                             args = conf_and_cons_list) conf_and_cons_df #>   CP_train CP_eval    DCP CPP_train  CPP_eval       DCPP #> 1    0.612   0.476 -0.136 0.6120000 0.4229075 -0.1890925 #> 2    0.668   0.568 -0.100 0.6391304 0.4653465 -0.1737839"},{"path":"https://bfakos.github.io/confcons/reference/thresholds.html","id":null,"dir":"Reference","previous_headings":"","what":"Thresholds needed to create the extended confusion matrix — thresholds","title":"Thresholds needed to create the extended confusion matrix — thresholds","text":"Calculate two thresholds distinguishing certain negatives/positives uncertain predictions. thresholds needed create extended confusion matrix used confidence calculation.","code":""},{"path":"https://bfakos.github.io/confcons/reference/thresholds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thresholds needed to create the extended confusion matrix — thresholds","text":"","code":"thresholds(observations, predictions = NULL, type = \"mean\", range = 0.5)"},{"path":"https://bfakos.github.io/confcons/reference/thresholds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Thresholds needed to create the extended confusion matrix — thresholds","text":"observations Either integer logical vector containing binary observations presences encoded 1s/TRUEs absences 0s/FALSEs. predictions numeric vector containing predicted probabilities occurrence typically within [0, 1] interval. length(predictions) equal length(observations) order elements match. predictions optional: needed used type 'mean' ignored otherwise. type character vector length one containing value 'mean' (calculating mean predictions within known presences absences) 'information' (calculating thresholds based relative information gain) . Defaults 'mean'. range numeric vector length one containing value ]0, 0.5] interval. parameter information-based method used type 'information'. larger range , predictions treated uncertain. Defaults 0.5.","code":""},{"path":"https://bfakos.github.io/confcons/reference/thresholds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Thresholds needed to create the extended confusion matrix — thresholds","text":"named numeric vector length 2. first element   ('threshold1') mean probabilities predicted absence   locations distinguishing certain negatives (certain absences)   uncertain predictions. second element ('threshold2') mean   probabilities predicted presence locations distinguishing certain   positives (certain presences) uncertain predictions. typical   model better random guess, first element smaller   second one. returned value might contain NaN(s) number   observed presences /absences 0.","code":""},{"path":"https://bfakos.github.io/confcons/reference/thresholds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Thresholds needed to create the extended confusion matrix — thresholds","text":"thresholds() called using whole dataset containing   training evaluation locations.","code":""},{"path":[]},{"path":"https://bfakos.github.io/confcons/reference/thresholds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Thresholds needed to create the extended confusion matrix — thresholds","text":"","code":"set.seed(12345)  # Using logical observations: observations_1000_logical <- c(rep(x = FALSE, times = 500),                                rep(x = TRUE, times = 500)) predictions_1000 <- c(runif(n = 500, min = 0, max = 0.7),                       runif(n = 500, min = 0.3, max = 1)) thresholds(observations = observations_1000_logical,            predictions = predictions_1000) # 0.370 0.650 #> threshold1 threshold2  #>  0.3703913  0.6492754   # Using integer observations: observations_4000_integer <- c(rep(x = 0L, times = 3000),                                rep(x = 1L, times = 1000)) predictions_4000 <- c(runif(n = 3000, min = 0, max = 0.8),                       runif(n = 1000, min = 0.2, max = 0.9)) thresholds(observations = observations_4000_integer,            predictions = predictions_4000) # 0.399 0.545 #> threshold1 threshold2  #>  0.3988011  0.5445960   # Wrong parameterization: if (FALSE) { thresholds(observations = observations_1000_logical,            predictions = predictions_4000) # error set.seed(12345) observations_4000_numeric <- c(rep(x = 0, times = 3000),                                rep(x = 1, times = 1000)) predictions_4000_strange <- c(runif(n = 3000, min = -0.3, max = 0.4),                               runif(n = 1000, min = 0.6, max = 1.5)) thresholds(observations = observations_4000_numeric,            predictions = predictions_4000_strange) # multiple warnings mask_of_normal_predictions <- predictions_4000_strange >= 0 & predictions_4000_strange <= 1 thresholds(observations = as.integer(observations_4000_numeric)[mask_of_normal_predictions],            predictions = predictions_4000_strange[mask_of_normal_predictions]) # OK }"},{"path":"https://bfakos.github.io/confcons/news/index.html","id":"confcons-020","dir":"Changelog","previous_headings":"","what":"confcons 0.2.0","title":"confcons 0.2.0","text":"thresholds() can now calculate information-based thresholds besides mean-based thresholds. Two new parameters (type range) added function. consistence() renamed consistency()","code":""},{"path":"https://bfakos.github.io/confcons/news/index.html","id":"confcons-010","dir":"Changelog","previous_headings":"","what":"confcons 0.1.0","title":"confcons 0.1.0","text":"new functions: thresholds(), confidence(), consistence() measures()","code":""}]
